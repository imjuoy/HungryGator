{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HungryGator\n",
    "## An Aggregator of Aggregators\n",
    "\n",
    "*Dev Pal Sross Gupta Subhadeep Bhattacharyya*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the below dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Run the below block to initialize all the dependencies\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import io, time, json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import scipy\n",
    "import warnings\n",
    "import io, time, json\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import punkt\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##The below block of code is used to read the API Key required for extracting data from Yelp fusion API.\n",
    "\n",
    "def read_api_key(filepath):\n",
    "    \"\"\"\n",
    "    Read the Yelp API Key from file.\n",
    "    \n",
    "    Args:\n",
    "        filepath (string): File containing API Key\n",
    "    Returns:\n",
    "        api_key (string): The API Key\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('api_key.txt', 'r') as f:\n",
    "        return f.read().replace('\\n','')\n",
    "\n",
    "def read_api_key_zomato(filepath):\n",
    "    \"\"\"\n",
    "    Read the Yelp API Key from file.\n",
    "    \n",
    "    Args:\n",
    "        filepath (string): File containing API Key\n",
    "    Returns:\n",
    "        api_key (string): The API Key\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('api_key_zomato.txt', 'r') as f:\n",
    "        return f.read().replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Extraction\n",
    "The below function takes in the api_key and the query and returns a total of 1000 restaurants along with their parameters including Name, Rating, Price, Reveiw Count, Url, Category, Zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##The function below is used to retrieve all the restaurants from the YELP API.\n",
    "\n",
    "def all_restaurants(api_key, query):\n",
    "    \"\"\"\n",
    "    Retrieve ALL the restaurants on Yelp for a given query.\n",
    "\n",
    "    Args:\n",
    "        query (string): Search term\n",
    "\n",
    "    Returns:\n",
    "        results (list): list of dicts representing each business\n",
    "    \"\"\"\n",
    "    \n",
    "    offsetno=0\n",
    "    total =0\n",
    "    output=[]\n",
    "    headers = {        \n",
    "        \"authorization\": 'Bearer %s' % api_key, # for the yelp API     \n",
    "    }\n",
    "    while (offsetno < 1000):\n",
    "        params = { #parameters are case sensitive!\n",
    "            \"location\": query,\n",
    "            \"limit\": 20,\n",
    "            \"offset\": offsetno,\n",
    "            \"categories\": \"restaurants\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "        response = requests.get('https://api.yelp.com/v3/businesses/search',\n",
    "                            headers=headers, params=params)\n",
    "        result = response.json()\n",
    "        try:\n",
    "            output.append( result['businesses'])\n",
    "        except KeyError:\n",
    "            print(result)\n",
    "            return output\n",
    "        offsetno =offsetno + 20\n",
    "        total = result['total']\n",
    "        #print (offsetno)\n",
    "        #print (len(output))\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Reading the API Key for accessing the Yelp API below. Passing the query parameter as Miami to select all\n",
    "## restaurants from Miami.\n",
    "\n",
    "api_key = read_api_key('api_key.txt')\n",
    "data = all_restaurants(api_key, 'Miami')\n",
    "new_data = {}\n",
    "new_data[\"name\"]=[]\n",
    "new_data[\"rating\"]=[]\n",
    "new_data[\"price\"]=[]\n",
    "new_data[\"review_count\"]=[]\n",
    "new_data[\"url\"]=[]\n",
    "new_data[\"category\"]=[]\n",
    "new_data[\"zip\"]=[]\n",
    "alldata=[]\n",
    "ids=[]\n",
    "name=[]\n",
    "zips=[]\n",
    "for i in data:\n",
    "    for each in i:\n",
    "        new_data[\"name\"].append(each[\"name\"])\n",
    "        new_data[\"rating\"].append(each[\"rating\"])\n",
    "        new_data[\"url\"].append(each[\"url\"])\n",
    "        try:\n",
    "            new_data[\"price\"].append(each[\"price\"])\n",
    "        except KeyError:\n",
    "            new_data[\"price\"].append(None)\n",
    "\n",
    "        new_data[\"review_count\"].append(each[\"review_count\"])\n",
    "        new_data[\"category\"].append(each[\"categories\"][0][\"title\"])\n",
    "        new_data[\"zip\"].append(each[\"location\"][\"zip_code\"])\n",
    "        ids.append(each[\"id\"])\n",
    "        name.append(each[\"name\"])\n",
    "        zips.append(each[\"location\"][\"zip_code\"])\n",
    "        alldata.append(each)\n",
    "\n",
    "yelp_raw = pd.DataFrame(alldata)\n",
    "yelp_clean = pd.DataFrame(new_data)\n",
    "yelp_clean['source'] = 'Yelp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below peice of code is executed to extract the actual value for prices. This is mandatory to ensure \n",
    "that prices have integer values and can be used for visualization later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Clean the price data coming from the YELP API.\n",
    "##Please run the block only after the above block is complete.\n",
    "\n",
    "def price(df):\n",
    "    try:\n",
    "        df[\"price\"]= len(df[\"price\"])\n",
    "    except:\n",
    "        df[\"price\"]=\"\"\n",
    "    return df\n",
    "yelp_clean= yelp_clean.apply(price,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function hits the YELP Fusion API again and fetches reviews for the restaurants that were fetched in the \n",
    "above query. This function is being called in the code block below and the data extracted is being used\n",
    "in generating the word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Retreive top 3 reviews for the restaurants retrieved from YELP. \n",
    "\n",
    "def get_reviews(ids,name):\n",
    "    headers = {        \n",
    "        \"authorization\": 'Bearer %s' % api_key, # for the yelp API     \n",
    "    }\n",
    "    restau_names=[]\n",
    "    output=[]\n",
    "    for i in range(len(ids)):\n",
    "        params = { #parameters are case sensitive!\n",
    "            \"locale\": \"en_US\",\n",
    "        }\n",
    "        url = \"https://api.yelp.com/v3/businesses/\"+str(ids[i])+\"/reviews\"\n",
    "        response = requests.get(url,\n",
    "                            headers=headers,params=params)\n",
    "        result = response.json()\n",
    "        output.append(result[\"reviews\"])\n",
    "        restau_names.append(name[i])\n",
    "    return output,restau_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Calling the function above and storing the Restaurant Name and Reviews in seperate lists.\n",
    "##This takes a while a to retrieve the data as it is extracting the data from YELP.\n",
    "\n",
    "reviews, restau_name = get_reviews(ids,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the data fetched in the above block to a CSV, since the API call is time consuming and can be an\n",
    "expensive operation to be run consecutively. \n",
    "The CSV acts as a one time data store for reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Writing the review data extracted from YELP to a CSV to avoid API call since, API call is time consuming.\n",
    "restau=[]\n",
    "text_reviews=[]\n",
    "loc_zip=[]\n",
    "for i in range(len(reviews)):\n",
    "    for each in reviews[i]:\n",
    "        text_reviews.append(each[\"text\"])\n",
    "#         print(i)\n",
    "        restau.append(name[i])\n",
    "        loc_zip.append(zips[i])\n",
    "d = {'restau_name':restau,'zip':loc_zip,'reviews':text_reviews}\n",
    "reviews_df = pd.DataFrame(d)\n",
    "reviews_df.to_csv(\"../DataFiles/reviews_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip Advisor Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##The below code needs to be executed to clean the TripAdvisor CSV file and create a raw and clean dataset out of it.\n",
    "\n",
    "trip_advisor_raw = pd.read_csv('../DataFiles/TripAdvisor_Data.csv')\n",
    "trip_advisor_clean = trip_advisor_raw[trip_advisor_raw[\"City\"]==\"Miami\"]\n",
    "trip_advisor_clean = trip_advisor_clean.loc[:,[\"Name\",\"Ranking\",\"Price\",\"Total Review\",\"Restaurant URL\",\"cuisine\",\"Address\",]]\n",
    "trip_advisor_clean.rename(index=str,columns={\"Name\":\"name\",\"Ranking\":\"rating\",\"Total Review\":\"review_count\",\"Restaurant URL\":\"url\",\"cuisine\":\"category\",\"Price\":\"price\"},inplace=True)\n",
    "trip_advisor_clean['source'] = 'Trip Advisor'\n",
    "trip_advisor_clean[\"check\"] = trip_advisor_clean[\"Address\"].str[-5:].str.isdigit()\n",
    "trip_advisor_clean = trip_advisor_clean[~trip_advisor_clean.Address.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Zip code is Trip Advisor needs to be extracted from the address to maintain a uniformity in the cleaned data.\n",
    "The below function returns the extracted zip from the address based on whether the address has a Zip or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Extracting the Zip code from address.\n",
    "\n",
    "def check(df):\n",
    "    try:\n",
    "        if df[\"check\"]==False:\n",
    "            df[\"new_zip\"]=\"\"\n",
    "        if df[\"check\"]==True and df[\"Address\"][-10:].find(\"-\")==-1:\n",
    "            df[\"new_zip\"]=df[\"Address\"][-5:]\n",
    "        if df[\"check\"]==False and df[\"Address\"][-10:].find(\"-\")!=-1:\n",
    "            df[\"new_zip\"]= df[\"Address\"][-10:][:df[\"Address\"][-10:].find(\"-\")]\n",
    "    except AttributeError: \n",
    "        df[\"new_zip\"]=\"\"\n",
    "    except TypeError:\n",
    "        df[\"new_zip\"]=\"\"\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calling the check function on the previously cleaned data.\n",
    "\n",
    "trip_advisor_clean= trip_advisor_clean.apply(check, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9b1351d9b5a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m##At the same time new zip column is renamed to zip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrip_advisor_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Address'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'check'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtrip_advisor_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"new_zip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"zip\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "##Since we need to maintain uniformity in cleaned data to Address and check columns are dropped.\n",
    "##At the same time new zip column is renamed to zip\n",
    "\n",
    "trip_advisor_clean.drop(columns=['Address', 'check'],inplace=True)\n",
    "trip_advisor_clean.rename(columns={\"new_zip\":\"zip\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zomato Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Below block of code is used to extract the data from the Zomato API.\n",
    "\n",
    "api_key_zomato = read_api_key_zomato('api_key_zomato.txt')\n",
    "\n",
    "headers = {'Content-Type': 'application/json', 'user-key': api_key_zomato}\n",
    "offset = 0\n",
    "restaurantNameList = []\n",
    "ratingList = []\n",
    "votesList = []\n",
    "urlList = []\n",
    "categoryList = []\n",
    "priceList = []\n",
    "zipList = []\n",
    "totalData = []\n",
    "while offset < 100:\n",
    "    url = 'https://developers.zomato.com/api/v2.1/search?entity_id=291&entity_type=city&start='+str(offset)+'&count=20'\n",
    "    Response = requests.get(url , headers=headers)\n",
    "    offset += 20\n",
    "    Response_Json = Response.json()\n",
    "    Array_length = Response_Json['restaurants']\n",
    "    for i in range(len(Array_length)):\n",
    "        totalData.append(Response_Json['restaurants'][i])\n",
    "        restaurantNameList.append(Response_Json['restaurants'][i]['restaurant']['name'])\n",
    "        ratingList.append(Response_Json['restaurants'][i]['restaurant']['user_rating']['aggregate_rating'])\n",
    "        votesList.append(Response_Json['restaurants'][i]['restaurant']['user_rating']['votes'])\n",
    "        urlList.append(Response_Json['restaurants'][i]['restaurant']['url'])\n",
    "        categoryList.append(Response_Json['restaurants'][i]['restaurant']['cuisines'])\n",
    "        priceList.append(Response_Json['restaurants'][i]['restaurant']['average_cost_for_two'])\n",
    "        zipList.append(Response_Json['restaurants'][i]['restaurant']['location']['zipcode'])\n",
    "zomato_raw = pd.DataFrame({'AllData':totalData})\n",
    "zomato_clean = pd.DataFrame({'name':restaurantNameList,'rating':ratingList,'price':priceList ,'review_count':votesList,'url':urlList,'category':categoryList,'zip':zipList})\n",
    "zomato_clean['source'] = 'Zomato'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##The below code will merge all the data frames to produce a merged dataset from the cleaned data.\n",
    "\n",
    "Merged_data = yelp_clean.append([trip_advisor_clean,zomato_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Rhe below block will create the excel file with the raw,cleaned and merged data.\n",
    "\n",
    "writer = pd.ExcelWriter('../DataFiles/Final_Data.xlsx' , engine='xlsxwriter')\n",
    "\n",
    "yelp_raw.to_excel(writer,'Yelp_Raw',index=False)\n",
    "yelp_clean.to_excel(writer,'Yelp_Clean',index=False)\n",
    "trip_advisor_raw.to_excel(writer, sheet_name = ' TripAdvisor_Raw')\n",
    "trip_advisor_clean.to_excel(writer, sheet_name = 'TripAdvisor_Clean')\n",
    "zomato_raw.to_excel(writer,sheet_name = 'Zomato_Raw')\n",
    "zomato_clean.to_excel(writer,sheet_name = 'Zomato_Clean')\n",
    "Merged_data.to_excel(writer,sheet_name = 'Merged_Data')\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Below is the code for the visualizations.\n",
    "##We read the data data sheet created above below.\n",
    "\n",
    "data = pd.ExcelFile('../DataFiles/Final_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Parsing the clean sheets below\n",
    "\n",
    "zomato = data.parse('Zomato_Clean')\n",
    "yelp = data.parse('Yelp_Clean')\n",
    "ta = data.parse('TripAdvisor_Clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross tabulation charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zomato Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binning the rating\n",
    "\n",
    "bins = [ 2.5, 3, 3.5, 4.0, 4.5, 5.0]\n",
    "\n",
    "# Creating a new column based on the rating\n",
    "\n",
    "zomato['ratingbucket'] = pd.cut(zomato['rating'], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zomato = zomato.sort_values('rating', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale= 1.5)\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.countplot(ax = ax, x='ratingbucket', data=zomato)\n",
    "plt.title('Zomato - Ratings')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Restaurants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zomato Price\n",
    "\n",
    "- We categorise the price from continuous to price segments that range from Low to Expensive based on quantiles\n",
    "- Plot the restaurant distribution based on these price segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sorting the zomato data\n",
    "\n",
    "zomato = zomato.sort_values('price', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Printing summary stats\n",
    "\n",
    "zomato.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sorting values\n",
    "\n",
    "zomato = zomato.sort_values('price', ascending=False)\n",
    "\n",
    "# Getting the 25th, 70th and 90th percentile to classify into 'Low','Medium' and 'Expensive'\n",
    "zomato.price.quantile(0.25)\n",
    "zomato.price.quantile(0.7)\n",
    "zomato.price.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorizing zomato's price segment \n",
    "zomato['price_segment'] = 'Cheap'\n",
    "zomato['price_segment'][zomato['price'] > 50] = 'Low'\n",
    "zomato['price_segment'][zomato['price'] > 100] = 'Moderate'\n",
    "zomato['price_segment'][zomato['price'] > 150] = 'Expensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting price for all reviews\n",
    "\n",
    "sns.set(font_scale= 1.5)\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.countplot(ax = ax, x='price_segment', data=zomato, order= ['Cheap','Low','Moderate','Expensive'])\n",
    "ax = plt.gca()\n",
    "#ax.set_xticklabels(['\\$','\\$$','\\$$\\$', '\\$\\$\\$$'])\n",
    "plt.title('Zomato - Price')\n",
    "plt.xlabel('price')\n",
    "plt.ylabel('Restaurants')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Rating\n",
    "\n",
    "- Plot restaurants by Yelp ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plotting ratings distribution for all reviews\n",
    "\n",
    "yelp = yelp.sort_values('rating', ascending=False)\n",
    "\n",
    "sns.set(font_scale= 1.5)\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.countplot(ax = ax, x='rating', data=yelp)\n",
    "plt.title('Yelp - Ratings')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Restaurants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Price\n",
    "\n",
    "- Plot Restaurants on Yelp by Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp = yelp.sort_values('price', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting price for all reviews for Yelp\n",
    "\n",
    "sns.set(font_scale= 1.5)\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.countplot(ax = ax, x='price', data=yelp)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_xticklabels(['\\$','\\$$','\\$$\\$', '\\$\\$\\$$'])\n",
    "plt.title('Yelp - Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Restaurants')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 Restaurant Categories and their Rating - YELP\n",
    "\n",
    "- We have hence categorized top 20 restaurants by price for YELP \n",
    "- Zomato says Cuban, Fast food and Mediterranean are rated highly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting the Top 20 Restaurant Categories and their rating for yelp\n",
    "\n",
    "yelp = yelp.sort_values('rating', ascending=False)\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "df = pd.crosstab(yelp.category,yelp.rating)\n",
    "df['total'] = df[2.5]+df[3.0]+ df[3.5]+ df[4.0] + df[4.5] + df[5.0]\n",
    "df = df.sort_values('total', ascending=False)\n",
    "del df['total']\n",
    "df.head(20).plot(ax=ax, kind='bar')\n",
    "plt.title('Restaurants and Restaurant category')\n",
    "plt.xlabel('Restaurant category')\n",
    "plt.ylabel('Restaurants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 Restaurant Categories and their Price - YELP\n",
    "\n",
    "- You can see that Sandwiches are cheap in Miami and Steakhouses are expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the Top 20 Restaurant Categories and their Price for yelp\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "df = pd.crosstab(yelp.category,yelp.price)\n",
    "df.columns = ['Cheap','Low','Moderate','Expensive']\n",
    "df['total'] = df['Cheap']+df['Low']+ df['Moderate']+ df['Expensive']\n",
    "df = df.sort_values('total', ascending=False)\n",
    "del df['total']\n",
    "df.head(20).plot(ax=ax, kind='bar')\n",
    "plt.title('Restaurants and Restaurant category')\n",
    "plt.xlabel('Restaurant category')\n",
    "plt.ylabel('Restaurants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 20 Restaurant Categories and their Rating - ZOMATO\n",
    "\n",
    "- You can see that Sandwiches are cheap in Miami and Steakhouses are expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zomato = zomato.sort_values('rating', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting the Top 20 Restaurant Categories and their rating for Zomato\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "# Preparing Cross tab data to plot\n",
    "df = pd.crosstab(zomato.category,zomato.ratingbucket)\n",
    "df.columns = [3.5,4.0,4.5,5.0]\n",
    "df['total'] = df[3.5]+ df[4.0] + df[4.5]+ df[5.0]\n",
    "df = df.sort_values('total', ascending=False)\n",
    "del df['total']\n",
    "\n",
    "\n",
    "# Plotting routine\n",
    "sns.set(font_scale=1.3)\n",
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "df.head(20).plot(ax=ax, kind='bar')\n",
    "plt.title('Restaurants and Restaurant category')\n",
    "plt.xlabel('Restaurant category')\n",
    "plt.ylabel('Restaurants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 20 Restaurant Categories and their Price - ZOMATO\n",
    "\n",
    "\n",
    "- Zomato says American, Seafood is cheap in Miami while Tex-Mex is expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating the crosstab data\n",
    "df = pd.crosstab(zomato.category,zomato.price_segment)\n",
    "df.columns = ['Cheap','Low','Moderate','Expensive']\n",
    "df['total'] = df['Cheap']+df['Low']+ df['Moderate']+ df['Expensive']\n",
    "df = df.sort_values('total', ascending=False)\n",
    "del df['total']\n",
    "\n",
    "\n",
    "# Plotting routine\n",
    "sns.set(font_scale=1.3)\n",
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "df.head(20).plot(ax=ax, kind='bar')\n",
    "plt.title('Restaurants and Restaurant category')\n",
    "plt.xlabel('Restaurant category')\n",
    "plt.ylabel('Restaurant ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip Advisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the restaurant ranking to rating\n",
    "\n",
    "- TripAdvisor data contains rankings of restaurants over the total number of restaurants in Miami\n",
    "- Our objective is to convert this ranking into rating so that we have homogeneity across our three site aggregators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There are in total 3600 restaurants\n",
    "ta.rating.str[-5:].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting the ranking for each restaurant\n",
    "\n",
    "ta['rating'] = ta.rating.str.split(' ').str[0].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dividing the restaurants on a scale of 3,600 total restaurants in Miami\n",
    "\n",
    "ta['rating'] = ta['rating'].astype(float)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting to a 5-scale\n",
    "\n",
    "ta['ratingpercentile'] = pd.qcut(ta.rating,100, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ta['ratingbucket'] = np.where(ta.rating.isnull(), np.nan, 5.0)\n",
    "\n",
    "# Top 10 percentile with rating 5\n",
    "ta['ratingbucket'][ta['ratingpercentile'] > 10] = 4.5\n",
    "# 10-30 percentile with 4.5\n",
    "ta['ratingbucket'][ta['ratingpercentile'] > 30] = 4.0\n",
    "# 30 -60 with 3.5\n",
    "ta['ratingbucket'][ta['ratingpercentile'] > 60] = 3.5\n",
    "# 60 - 80 with 3.0\n",
    "ta['ratingbucket'][ta['ratingpercentile'] > 80] = 3.0\n",
    "# 80 - 90 with 2.5\n",
    "ta['ratingbucket'][ta['ratingpercentile'] > 90] = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TripAdvisor Restaurants by Rating\n",
    "\n",
    "- Plot TripAdvisors restaurants by their rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ta = ta.sort_values('rating', ascending=False)\n",
    "\n",
    "sns.set(font_scale= 1.5)\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.countplot(ax = ax, x='ratingbucket', data=ta)\n",
    "plt.title('Trip Advisor - Ratings')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Restaurants')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing restaurants across different sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating comparison Yelp vs Zomato\n",
    "\n",
    "- We compare Restaurants on Yelp against Restaurants on Zomato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing dataset for comparison between Yelp TA and Zomato\n",
    "\n",
    "comb = pd.merge(pd.DataFrame(zomato.loc[:,['name','rating','zip']]), pd.DataFrame(yelp.loc[:,['name','rating','zip']]), how = 'inner', on = ['name','zip'])\n",
    "\n",
    "comb.columns = ['name','Zomato Rating','zip','Yelp Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We see that Restaurants are rated higher on Zomato than on Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "comb.plot(kind='bar', x = 'name',y = ['Zomato Rating','Yelp Rating'], figsize=(15,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating comparison Yelp vs Ta vs Zomato\n",
    "\n",
    "- We see that restaurants in Miami are rated lowest on Yelp than on Zomato and TripAdvisor.\n",
    "- Assumption: TripAdvisor's ranking was converted to ranking. But on the balance, we do see a comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb2 = pd.merge( pd.DataFrame(ta.loc[:,['name','ratingbucket']]),comb, how = 'inner', on = 'name')\n",
    "\n",
    "comb2.columns = ['name','TripAdvisor Rating','Zomato Rating','zip','Yelp Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.3)\n",
    "comb2.plot(kind='bar', x = 'name',y = ['Yelp Rating', 'TripAdvisor Rating', 'Zomato Rating'], figsize=(12,7))\n",
    "plt.xlabel('Restaurant Name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences**\n",
    "\n",
    "- Now that we see that there is substantial rating differences between same restaurants in Yelp and Zomato, we need to offer the users with possible reasons for the difference.\n",
    "\n",
    "- Since we see ratings from Zomato is almost always higher than ratings from Yelp, we can speculate that there might be lesser number of reviews in Zomato as compared to Yelp. Number of reviews generally tends to reduce the average ratings of restaurants due to varied opinions. However, this is not mandatory. There are chances that people might have actually given higher ratings to same restaurant in Zomato. To find this out, we will need to tally the review count for the common restaurants across both the platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Count Comparison Yelp vs Zomato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb4 = pd.merge(zomato, yelp, how = 'inner', on = 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.3)\n",
    "\n",
    "comb4.plot(kind='bar', x = 'name',y = ['yelp_review_count','zomato_review_count'], figsize=(15,5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph validates our prediction for some of the restaurants. For the first restaurant \"Versailles Restaurant\", we see that the number of reviews of Yelp is substanitally higher than Zomato. This further suggests why rating in Zomato for the same restaurant is higher than the rating in Yelp. With the increase in visitors the restaurant probably was not able to maintain it's quality or probably there are higher number of people in Miami that use Yelp as compared to Zomato.\n",
    "Similarly for \"Villagio\" we can see that the number of reviews in Zomato is higher than the number of reviews in Yelp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Count Comparison Yelp vs Zomato vs Trip Advisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.3)\n",
    "\n",
    "comb2.plot(kind='bar', x = 'name',y = ['ta_review_count','yelp_review_count','zomato_review_count'], figsize=(12,7))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud by Zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reviews= pd.read_csv(\"../DataFiles/reviews_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datacleaning(df):\n",
    "    #removing @\n",
    "    df[\"reviews\"]= df.apply(lambda row: re.sub(r'@[\\w0-9]+','',row[\"reviews\"],re.IGNORECASE), axis=1)\n",
    "    #removing URL tags\n",
    "    df[\"reviews\"]= df.apply(lambda row: re.sub(r'https?://[\\w0-9./]+','',row[\"reviews\"],re.IGNORECASE), axis=1)\n",
    "    df[\"reviews\"]= df.apply(lambda row: re.sub(r'www.[^ ]+','',row[\"reviews\"],re.IGNORECASE), axis=1)\n",
    "    \n",
    "    #removing Byte order marks\n",
    "    df[\"reviews\"]= df.apply(lambda row: row[\"reviews\"].replace(u\"\\ufffd\", \"?\"), axis=1)\n",
    "    #Convert the data to lowercase\n",
    "    df[\"reviews\"]= df.apply(lambda row: row[\"reviews\"].lower(), axis=1)    \n",
    "    #removing hashtag/numbers and punctuations\n",
    "    df[\"reviews\"]= df.apply(lambda row: re.sub(r\"[^a-zA-Z ]+\",'',row[\"reviews\"]), axis=1)\n",
    "    return df\n",
    "df_reviews = datacleaning(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_length(text):\n",
    "    tokenizer = nltk.tokenize.word_tokenize\n",
    "    words = tokenizer(text)\n",
    "    fin=[]\n",
    "    for word in words:\n",
    "        if len(word)>1:\n",
    "            fin.append(word)\n",
    "    return \" \".join(fin)    \n",
    "df_reviews[\"reviews\"] = df_reviews[\"reviews\"].apply(handle_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_data_byzip(df,zip_code):\n",
    "    df_ = df.copy()\n",
    "    df_ = df_[df_[\"zip\"]==zip_code]\n",
    "    return \" \".join(list(df_[\"reviews\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please select a zip code from the below list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f(zip_code):\n",
    "    reviews_list= filter_data_byzip(df_reviews,zip_code)\n",
    "    wc = WordCloud(width=1600, height=800,max_font_size=200,stopwords=nltk.corpus.stopwords.words('english')\\\n",
    "                         , colormap=\"viridis\").generate(reviews_list)\n",
    "    plt.figure(figsize=(20,18))\n",
    "    plt.imshow(wc, interpolation=\"bicubic\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    return (wc,zip_code)\n",
    "a= interactive(f, zip_code=df_reviews[\"zip\"].unique());\n",
    "display(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending top restaurant based on ratings by a zip code\n",
    "\n",
    "- In this section, we want to recommend 3 restaurants to our user based on\n",
    "    - Zipcode - The area where the restaurant is located\n",
    "    - Price/Rating - The price segment of the restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting the required data\n",
    "\n",
    "new_df = pd.ExcelFile('../DataFiles/Final_Data.xlsx')\n",
    "new_df = new_df.parse(\"Merged_Data\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "\n",
    "new_df= new_df[~new_df[\"zip\"].isnull()]\n",
    "new_df[\"zip\"]= new_df[\"zip\"].astype(int)\n",
    "df = new_df[[\"name\",\"rating\",\"source\",\"price\",\"zip\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reference: http://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html\n",
    "b= widgets.ToggleButtons(\n",
    "    options=['price', 'rating'],\n",
    "    description='Criteria:',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accc05a4770d45d8894ccb83696ca669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Writing a method that would give us the top restaurants on different sites based on zipcode and criteria\n",
    "\n",
    "def f1(zip_code, criteria):\n",
    "    print(\"--- Recommendations based on\",criteria,\" ---\")\n",
    "    df2 = df[df[\"zip\"]==zip_code]\n",
    "    df2 = df2[[\"name\",\"rating\",\"source\",\"price\",\"zip\"]]\n",
    "    df_yelp = df2[df2[\"source\"]==\"Yelp\"]\n",
    "    df_ta = df2[df2[\"source\"]==\"Trip Advisor\"]\n",
    "    df_zomato = df2[df2[\"source\"]==\"Zomato\"]\n",
    "    print(\"Yelp recommended restaurants:\",df_yelp.sort_values(criteria, ascending=False)[\"name\"].values[:3])\n",
    "    print(\"Zomato recommended restaurants:\",df_zomato.sort_values(criteria, ascending=False)[\"name\"].values[:3])\n",
    "    print(\"Trip Advisor recommended restaurants:\",df_ta.sort_values(criteria, ascending=False)[\"name\"].values[:3])\n",
    "    \n",
    "interact(f1, zip_code=df[\"zip\"].unique(),criteria = b );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hungrygator© "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
