{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import io, time, json\n",
    "\n",
    "##Below block of code is used to extract the data from the Zomato API.\n",
    "global writer\n",
    "writer = pd.ExcelWriter('../DataFiles/Final_Data.xlsx' , engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The below block of code is used to read the API Key required for extracting data from Yelp fusion API.\n",
    "\n",
    "def read_api_key(filepath):\n",
    "    \"\"\"\n",
    "    Read the Yelp API Key from file.\n",
    "    \n",
    "    Args:\n",
    "        filepath (string): File containing API Key\n",
    "    Returns:\n",
    "        api_key (string): The API Key\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('api_key.txt', 'r') as f:\n",
    "        return f.read().replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The function below is used to retrieve all the restaurants from the YELP API.\n",
    "\n",
    "def all_restaurants(api_key, query):\n",
    "    \"\"\"\n",
    "    Retrieve ALL the restaurants on Yelp for a given query.\n",
    "\n",
    "    Args:\n",
    "        query (string): Search term\n",
    "\n",
    "    Returns:\n",
    "        results (list): list of dicts representing each business\n",
    "    \"\"\"\n",
    "    \n",
    "    offsetno=0\n",
    "    total =0\n",
    "    output=[]\n",
    "    headers = {        \n",
    "        \"authorization\": 'Bearer %s' % api_key, # for the yelp API     \n",
    "    }\n",
    "    while (offsetno < 1000):\n",
    "        params = { #parameters are case sensitive!\n",
    "            \"location\": query,\n",
    "            \"limit\": 20,\n",
    "            \"offset\": offsetno,\n",
    "            \"categories\": \"restaurants\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "        response = requests.get('https://api.yelp.com/v3/businesses/search',\n",
    "                            headers=headers, params=params)\n",
    "        result = response.json()\n",
    "        try:\n",
    "            output.append( result['businesses'])\n",
    "        except KeyError:\n",
    "            print(result)\n",
    "            return output\n",
    "        offsetno =offsetno + 20\n",
    "        total = result['total']\n",
    "        #print (offsetno)\n",
    "        #print (len(output))\n",
    "    return(output)\n",
    "\n",
    "api_key = read_api_key('api_key.txt')\n",
    "data = all_restaurants(api_key, 'Miami')\n",
    "new_data = {}\n",
    "new_data[\"name\"]=[]\n",
    "new_data[\"rating\"]=[]\n",
    "new_data[\"price\"]=[]\n",
    "new_data[\"review_count\"]=[]\n",
    "new_data[\"url\"]=[]\n",
    "new_data[\"category\"]=[]\n",
    "new_data[\"zip\"]=[]\n",
    "new_data[\"Source\"]=[]\n",
    "alldata=[]\n",
    "for i in data:\n",
    "    for each in i:\n",
    "        new_data[\"name\"].append(each[\"name\"])\n",
    "        new_data[\"rating\"].append(each[\"rating\"])\n",
    "        new_data[\"url\"].append(each[\"url\"])\n",
    "        try:\n",
    "            new_data[\"price\"].append(each[\"price\"])\n",
    "        except KeyError:\n",
    "            new_data[\"price\"].append(None)\n",
    "\n",
    "        new_data[\"review_count\"].append(each[\"review_count\"])\n",
    "        new_data[\"category\"].append(each[\"categories\"][0][\"title\"])\n",
    "        new_data[\"zip\"].append(each[\"location\"][\"zip_code\"])\n",
    "        new_data[\"Source\"].append('Yelp')\n",
    "        alldata.append(each)\n",
    "writer = pd.ExcelWriter('../DataFiles/Final_Data.xlsx' , engine='xlsxwriter')\n",
    "df4 = pd.DataFrame(alldata)\n",
    "df4.to_excel(writer,'YelpRaw',index=False)\n",
    "df3 = pd.DataFrame(new_data)\n",
    "df3.to_excel(writer,'YelpClean',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subhadeepbhattacharyya/anaconda3/lib/python3.6/site-packages/xlsxwriter/worksheet.py:830: UserWarning: Ignoring URL 'http://epc7.domaingateway.com/c?pid=11163370-367280&kw=writing restaurant reviews&c=ad3f7cf9c0b14d06a873a2f707811dfa-wuu.kf.3k.w3S%0972atQI%2FwU.f.3ws.kw+%28s.F.k.w%2C+aWA0+s.w.s+%28sfwk-fS-fu%29%29%09wkfwskswS4Uw4%09s4U%09A0%09zWLXIL2jWNIL%092vvRN%3A%2F%2FRw.oLvaEH.EtQ%2Fva%3Fqo%3DFUusuj33wSUEwEUuISIA33wAossOjsoOwOj4SSEI.a%09%5BLWii%5D%09f.fwUw%09f.fwUw%09%5BLWii%5D%09OjiNI%09Fkf%09wfS344ku4u%099TmhgD%09%5BLWii%5D%09aIQqLzvtLNtOAtNvtL.EtQ%09f%09w3s.wUu.f.w3k%09%5BLWii%5D%09%5BLWii%5D%09wkw%7Ewkw%094SSjuF3E-E3S4-kEff-jFUU-So4oF3kkouU3%09%5BLWii%5D%09&r=1&ptt=' with link or location/anchor > 255 characters since it exceeds Excel's limit for URLS\n",
      "  force_unicode(url))\n",
      "/Users/subhadeepbhattacharyya/anaconda3/lib/python3.6/site-packages/xlsxwriter/worksheet.py:830: UserWarning: Ignoring URL 'http://local.subway.com/fwpcons/frmResult.aspx?ResultMsg=%3cfont%20size='6'%3eOops!%3c/font%3e%3cbr/%3eWe're%20sorry,%20the%20page%20you%20are%20looking%20for%20is%20either%20not%20found%20or%20has%20generated%20this%20error.%20%20If%20this%20occurs%20regularly,%20please%20contact%20the%20SUBWAY%20%20Web%20Team.&Error=1' with link or location/anchor > 255 characters since it exceeds Excel's limit for URLS\n",
      "  force_unicode(url))\n",
      "/Users/subhadeepbhattacharyya/anaconda3/lib/python3.6/site-packages/xlsxwriter/worksheet.py:830: UserWarning: Ignoring URL 'http://maps.google.com/maps/place?oe=utf-8&rls=org.mozilla:en-US:official&client=firefox-a&um=1&ie=UTF-8&q=the%20viking%20tavern%20spokane%20wa&fb=1&gl=us&hq=the%20viking%20tavern&hnear=0x549e185c30bbe7e5:0xddfcc9d60b84d9b1,Spokane,%20WA&cid=7286429845809543666&ei=UEtuToOxFaLjiALM7rSgDg&sa=X&oi=local_result&ct=placepage-link&resnum=1&ved=0CB8Q4gkwAA' with link or location/anchor > 255 characters since it exceeds Excel's limit for URLS\n",
      "  force_unicode(url))\n",
      "/Users/subhadeepbhattacharyya/anaconda3/lib/python3.6/site-packages/xlsxwriter/worksheet.py:830: UserWarning: Ignoring URL 'http://www.hojo.com/hotels/florida/hialeah-gardens/howard-johnson-plaza-hotel-miami-airport/hotel-dining?partner_id=&hotel_id=14809&campaign_code=&propId=HJ14809&checkout_date&brand_id=HJ&children=0&corporate_id&ratePlan&teens=0&affiliate_id=&iata=&rate_code&adults=1&checkin_date&rooms=1' with link or location/anchor > 255 characters since it exceeds Excel's limit for URLS\n",
      "  force_unicode(url))\n"
     ]
    }
   ],
   "source": [
    "##The below code needs to be executed to clean the TripAdvisor CSV file and create a raw and clean dataset out of it.\n",
    "\n",
    "data = pd.read_csv('../DataFiles/TripAdvisor_Data.csv')\n",
    "cleaned_data = data[data[\"City\"]==\"Miami\"]\n",
    "cleaned_data = cleaned_data.loc[:,[\"Restaurant ID\", \"Restaurant URL\",\"Name\",\"Address\",\"Ranking\",\"Total Review\"]]\n",
    "#path = r\"C:/Users/devdi/Desktop/CMU/Final Mini/Python for Data Science/Project/Data.xlsx\"\n",
    "#writer = pd.ExcelWriter(path, engine = 'xlsxwriter')\n",
    "data.to_excel(writer, sheet_name = ' TripAdvisor_raw')\n",
    "cleaned_data.to_excel(writer, sheet_name = 'TripAdvisor_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Content-Type': 'application/json', 'user-key': '592789033e4cf0e384b54c1ec424c706'}\n",
    "offset = 0\n",
    "restaurantNameList = []\n",
    "ratingList = []\n",
    "ratingTextList = []\n",
    "votesList = []\n",
    "totalData = []\n",
    "urlList = []\n",
    "addressList = []\n",
    "sourceList = []\n",
    "while offset < 100:\n",
    "    url = 'https://developers.zomato.com/api/v2.1/search?entity_id=291&entity_type=city&start='+str(offset)+'&count=20'\n",
    "    Response = requests.get(url , headers=headers)\n",
    "    offset += 20\n",
    "    Response_Json = Response.json()\n",
    "    Array_length = Response_Json['restaurants']\n",
    "    for i in range(len(Array_length)):\n",
    "        totalData.append(Response_Json['restaurants'][i])\n",
    "        restaurantNameList.append(Response_Json['restaurants'][i]['restaurant']['name'])\n",
    "        ratingList.append(Response_Json['restaurants'][i]['restaurant']['user_rating']['aggregate_rating'])\n",
    "        ratingTextList.append(Response_Json['restaurants'][i]['restaurant']['user_rating']['rating_text'])\n",
    "        votesList.append(Response_Json['restaurants'][i]['restaurant']['user_rating']['votes'])\n",
    "        urlList.append(Response_Json['restaurants'][i]['restaurant']['url'])\n",
    "        addressList.append(Response_Json['restaurants'][i]['restaurant']['location']['address'])\n",
    "        sourceList.append('Zomato')\n",
    "df1 = pd.DataFrame({'AllData':totalData})\n",
    "df2 = pd.DataFrame({'Restaurant Name':restaurantNameList,'Rating':ratingList, 'Rating Text':ratingTextList, 'Votes':votesList, 'Url':urlList, 'Address': addressList, 'Source': sourceList})\n",
    "df1.to_excel(writer,sheet_name = 'Zomato_raw')\n",
    "df2.to_excel(writer,sheet_name = 'Zomato_clean')\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
